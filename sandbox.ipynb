{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evan/code/thesis/src/utils.py:81: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(sum([len(ixs)!=2 for ixs in token_ixs]), f\"Offsets not lining up for mention in {file}\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "class obj:\n",
    "    # constructor\n",
    "    def __init__(self, dict1):\n",
    "        self.__dict__.update(dict1)\n",
    "args = {\n",
    "    \"candidates\": 20,\n",
    "    \"device\": 'mps',\n",
    "    'output_dir': 'tmp/local',\n",
    "    \"dev_dir\":'datasets/development/processed_dev',\n",
    "    \"train_dir\":'datasets/development/processed_dev',\n",
    "    \"test_dir\":'datasets/development/processed_dev',\n",
    "    \"dictionary_path\": 'datasets/development/dev_dictionary.txt',\n",
    "    \"max_length\": 25,\n",
    "    \"model_name_or_path\": 'dmis-lab/biobert-base-cased-v1.1',\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 1,\n",
    "    \"loss_fn\": \"similarity_nll\",\n",
    "    \"contextualized\": False,\n",
    "    \"similarity_type\": 'log'\n",
    "}\n",
    "args = json.loads(json.dumps(args), object_hook=obj)\n",
    "vars(args)\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "# Local modules\n",
    "from src.candidateDataset import CandidateDataset\n",
    "from src.rerankNet import RerankNet\n",
    "from src.umls import Umls\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/17/2022 08:32:36 AM: [ <__main__.obj object at 0x105a05ac0> ]\n",
      "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "07/17/2022 08:32:40 AM: [ UMLS data loaded ]\n",
      "100%|██████████| 179/179 [00:00<00:00, 1443808.49it/s]\n",
      "07/17/2022 08:32:40 AM: [ Dictionary loaded ]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2102.94it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 5026.13it/s]\n",
      "07/17/2022 08:32:40 AM: [ Mentions loaded ]\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "start = time.time()\n",
    "LOGGER = utils.init_logging()\n",
    "LOGGER.info(args)\n",
    "utils.init_seed(42)\n",
    "bert = AutoModel.from_pretrained(args.model_name_or_path).to(args.device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "\n",
    "# Set loss function\n",
    "if args.loss_fn=='nll':\n",
    "    loss_fn = utils.marginal_nll\n",
    "elif args.loss_fn=='similarity_nll':\n",
    "    loss_fn = utils.similarity_nll\n",
    "elif args.loss_fn=='mse':\n",
    "    loss_fn = utils.mse_loss\n",
    "elif args.loss_fn=='mse5':\n",
    "    loss_fn = utils.mse5_loss\n",
    "else:\n",
    "    raise Exception(f\"Invalid loss function {args.loss_fn}\")\n",
    "    \n",
    "# Build model\n",
    "model = RerankNet(encoder=bert, tokenizer=tokenizer, device=args.device)\n",
    "\n",
    "# Load UMLS data\n",
    "umls = Umls('umls/processed')\n",
    "LOGGER.info(\"UMLS data loaded\")\n",
    "\n",
    "# Load dictionary\n",
    "dictionary = utils.load_dictionary(args.dictionary_path)\n",
    "LOGGER.info(\"Dictionary loaded\")\n",
    "\n",
    "# Load training data\n",
    "train_mentions = utils.load_mentions(args.train_dir)\n",
    "train_set = CandidateDataset(train_mentions, dictionary, model.tokenizer, args.max_length, args.candidates, args.similarity_type, umls) \n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "# Load dev data for validation\n",
    "dev_mentions = utils.load_mentions(args.dev_dir)\n",
    "LOGGER.info(\"Mentions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bulk embedding...: 100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "Bulk embedding...: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s]\n",
      "07/17/2022 08:32:49 AM: [ Epoch 0: max possible acc@1 = 0.875 ]\n",
      "Training epoch 0:   0%|          | 0/1 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::logical_and.out' is not current implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/evan/code/thesis/sandbox.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/evan/code/thesis/sandbox.ipynb#ch0000002?line=26'>27</a>\u001b[0m batch_pred \u001b[39m=\u001b[39m model(batch_x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/evan/code/thesis/sandbox.ipynb#ch0000002?line=27'>28</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(batch_pred, batch_y\u001b[39m.\u001b[39mto(args\u001b[39m.\u001b[39mdevice))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/evan/code/thesis/sandbox.ipynb#ch0000002?line=28'>29</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/evan/code/thesis/sandbox.ipynb#ch0000002?line=29'>30</a>\u001b[0m model\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/evan/code/thesis/sandbox.ipynb#ch0000002?line=30'>31</a>\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/BioSyn/lib/python3.8/site-packages/torch/_tensor.py:400\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    392\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    393\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    394\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    398\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    399\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 400\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/BioSyn/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::logical_and.out' is not current implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epoch_results = pd.DataFrame([], columns=['acc@1','acc@5','umls_similarity', 'max_acc@1'])\n",
    "for epoch in range(args.epochs):\n",
    "        ############## Candidate Generation ##############\n",
    "        train_candidate_idxs = utils.get_topk_candidates(\n",
    "                dict_names=list(dictionary[:,0]), \n",
    "                mentions=train_mentions, \n",
    "                tokenizer=model.tokenizer, \n",
    "                encoder=model.encoder, \n",
    "                max_length=args.max_length, \n",
    "                device=args.device, \n",
    "                topk=args.candidates)\n",
    "                                \n",
    "        # Add candidates to training dataset\n",
    "        train_set.set_candidate_idxs(train_candidate_idxs)\n",
    "        max_acc1 = train_set.max_acc1()\n",
    "        LOGGER.info('Epoch {}: max possible acc@1 = {}'.format(epoch,max_acc1))\n",
    "\n",
    "        ###################### Train ######################\n",
    "        # Train encoder to properly rank candidates\n",
    "        train_loss = 0\n",
    "        train_steps = 0\n",
    "        model.train()\n",
    "        for i, data in tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Training epoch {epoch}'):\n",
    "                model.optimizer.zero_grad()\n",
    "                batch_x, batch_y = data\n",
    "                batch_pred = model(batch_x)\n",
    "                loss = loss_fn(batch_pred, batch_y.to(args.device))\n",
    "                loss.backward()\n",
    "                model.optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                train_steps += 1\n",
    "\n",
    "        train_loss = train_loss / (train_steps + 1e-9)\n",
    "        LOGGER.info('Epoch {}: loss/train_per_epoch={}/{}'.format(epoch,train_loss,epoch))\n",
    "\n",
    "        #################### Evaluate ####################\n",
    "        # Get candidates on dev dataset\n",
    "        dev_candidate_idxs = utils.get_topk_candidates(\n",
    "                dict_names=list(dictionary[:,0]), \n",
    "                mentions=dev_mentions, \n",
    "                tokenizer=model.tokenizer, \n",
    "                encoder=model.encoder, \n",
    "                max_length=args.max_length, \n",
    "                device=args.device, \n",
    "                topk=5) # Only need top five candidates to evaluate performance\n",
    "\n",
    "        # Log performance on dev after each epoch\n",
    "        results = utils.evaluate(dev_mentions, dictionary[dev_candidate_idxs], umls)\n",
    "        epoch_results.loc[epoch] = (results['acc1'], results['acc5'], results['umls_similarity'], max_acc1)\n",
    "        LOGGER.info(\"Epoch {}: acc@1={}\".format(epoch,results['acc1']))\n",
    "        LOGGER.info(\"Epoch {}: acc@5={}\".format(epoch,results['acc5']))\n",
    "        LOGGER.info(\"Epoch {}: umls_similarity={}\".format(epoch,results['umls_similarity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/17/2022 07:40:22 AM: [ Loading epoch 0 model from tmp/local/checkpoint_0 ]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1731.75it/s]\n",
      "Bulk embedding...: 100%|██████████| 1/1 [00:17<00:00, 17.72s/it]\n",
      "Bulk embedding...: 100%|██████████| 1/1 [00:04<00:00,  4.73s/it]\n",
      "07/17/2022 07:41:00 AM: [ Test result: acc@1=0.875 ]\n",
      "07/17/2022 07:41:00 AM: [ Test result: acc@5=0.875 ]\n",
      "07/17/2022 07:41:00 AM: [ Test result: umls_similarity=0.9166666666666666 ]\n",
      "07/17/2022 07:41:00 AM: [ Prediction time: 0 hours 0 minutes 38 seconds ]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data using best training model\n",
    "start = time.time()\n",
    "best_epoch = epoch_results.umls_similarity.argmax()\n",
    "train_model_path = os.path.join(args.output_dir, \"checkpoint_{}\".format(best_epoch))\n",
    "LOGGER.info(f'Loading epoch {best_epoch} model from {train_model_path}')\n",
    "\n",
    "# Load training model\n",
    "train_bert = AutoModel.from_pretrained(train_model_path).to(args.device)\n",
    "train_tokenizer = AutoTokenizer.from_pretrained(train_model_path)\n",
    "\n",
    "# Load test mentions\n",
    "test_mentions = utils.load_mentions(args.test_dir)\n",
    "\n",
    "# Predict topk=5 candidates\n",
    "candidate_idxs = utils.get_topk_candidates(\n",
    "        dict_names=list(dictionary[:,0]), \n",
    "        mentions=test_mentions, \n",
    "        tokenizer=train_tokenizer, \n",
    "        encoder=train_bert, \n",
    "        max_length=args.max_length, \n",
    "        device=args.device, \n",
    "        topk=5, # Only need top five candidates to evaluate performance\n",
    "        doc_dir=None) # Update to allow contextualized embeddings\n",
    "\n",
    "# Log performance\n",
    "results = utils.evaluate(test_mentions, dictionary[candidate_idxs], umls)\n",
    "LOGGER.info(\"Test result: acc@1={}\".format(results['acc1']))\n",
    "LOGGER.info(\"Test result: acc@5={}\".format(results['acc5']))\n",
    "LOGGER.info(\"Test result: umls_similarity={}\".format(results['umls_similarity']))\n",
    "\n",
    "LOGGER.info('Prediction time: ' + utils.format_time(start,time.time()))\n",
    "\n",
    "# Write output\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir)\n",
    "output_file = os.path.join(args.output_dir,\"predictions_eval.json\")\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evan/code/thesis/src/utils.py:79: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  # Check all annotations were fixed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'src.utils' from '/Users/evan/code/thesis/src/utils.py'>"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.utils as utils\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/BioSyn/lib/python3.8/site-packages/torch/_tensor_str.py:103: UserWarning: The operator 'aten::bitwise_and.Tensor_out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  nonzero_finite_vals = torch.masked_select(tensor_view, torch.isfinite(tensor_view) & tensor_view.ne(0))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.0818, device='mps:0', grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, target = batch_pred, batch_y.to(args.device)\n",
    "\n",
    "def similarity_nll(score, target):\n",
    "    \"Negative log likelihood of predicted similarity matching max candidate similarity\"\n",
    "    # Assign probabilities to each candidate\n",
    "    preds = torch.nn.functional.softmax(score, dim=-1)\n",
    "\n",
    "    # Aggregate predictions to a single similarity score\n",
    "    pred_similarity = torch.sum(preds * target, dim=1)\n",
    "\n",
    "    # Find max possible similarity given available candidates\n",
    "    max_similarity = torch.max(target, dim=1).values\n",
    "\n",
    "    # Avoid divide by zero in case of candidates all having zero similarity\n",
    "    pred_similarity = torch.clamp(pred_similarity, min=1e-9, max=1)\n",
    "    max_similarity = torch.clamp(max_similarity, min=1e-9, max=1)\n",
    "\n",
    "    # Calculate loss out of max_similarity, rather than 1\n",
    "    pred_similarity = pred_similarity / max_similarity\n",
    "    return -torch.log(pred_similarity).mean()\n",
    "similarity_nll(score, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0211, 0.1000, 0.0500, 0.0500, 0.0500, 0.1500, 0.4000, 1.0000],\n",
      "       device='mps:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.2454, device='mps:0', grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pred_similarity)\n",
    "-torch.log(pred_similarity).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evan/code/thesis/src/utils.py:80: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(sum([len(ixs)!=2 for ixs in token_ixs]), f\"Offsets not lining up for mention in {file}\")\n",
      "/Users/evan/code/thesis/src/utils.py:80: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(sum([len(ixs)!=2 for ixs in token_ixs]), f\"Offsets not lining up for mention in {file}\")\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::index.Tensor' is not current implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/evan/code/thesis/sandbox.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/evan/code/thesis/sandbox.ipynb#ch0000011?line=0'>1</a>\u001b[0m utils\u001b[39m.\u001b[39;49mmarginal_nll(score, target)\n",
      "File \u001b[0;32m~/code/thesis/src/utils.py:150\u001b[0m, in \u001b[0;36mmarginal_nll\u001b[0;34m(score, target)\u001b[0m\n\u001b[1;32m    148\u001b[0m loss \u001b[39m=\u001b[39m predict \u001b[39m*\u001b[39m target\n\u001b[1;32m    149\u001b[0m loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)                   \u001b[39m# sum all positive scores\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m loss \u001b[39m=\u001b[39m loss[loss \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m]                     \u001b[39m# drop predictions which didn't have gold_cui available in the candidates\u001b[39;00m\n\u001b[1;32m    151\u001b[0m loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mclamp(loss, \u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1e-9\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# for numerical stability\u001b[39;00m\n\u001b[1;32m    152\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mtorch\u001b[39m.\u001b[39mlog(loss)                   \u001b[39m# for negative log likelihood\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::index.Tensor' is not current implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "utils.marginal_nll(score, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1250, device='mps:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse_loss(score, target):\n",
    "    \"Calculates MSE loss between max similarity of the candidates and similarity of top prediction\"\n",
    "    # Find similarity of the top prediction\n",
    "    pred_ixs = score.argmax(dim=1)\n",
    "    predicted_similarity = torch.gather(target, 1, pred_ixs.unsqueeze_(dim=1)).squeeze().requires_grad_()\n",
    "\n",
    "    # Find max similarity for each mention of the available candidates\n",
    "    expected_similarity = torch.max(target, dim=1).values\n",
    "    return torch.nn.functional.mse_loss(expected_similarity, predicted_similarity)\n",
    "\n",
    "mse_loss(batch_pred, batch_y.to(args.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2500, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, target = batch_pred, batch_y.to(args.device)\n",
    "pred_ixs = score.argmax(dim=1)\n",
    "predicted_similarity = torch.gather(target, 1, pred_ixs.unsqueeze_(dim=1)).squeeze().requires_grad_()\n",
    "predicted_similarity # was it correct?\n",
    "\n",
    "expected_similarity = torch.max(target, dim=1).values # was the correct CUI available?\n",
    "torch.nn.functional.mse_loss(expected_similarity, predicted_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The network fails to train when using the following loss function.\n",
    "The network is able to successfully train when using other loss functions, so \n",
    "this function appears to be the most likely point of failure.\n",
    "\"\"\"\n",
    "\n",
    "def mse_loss(score, target):\n",
    "    \"\"\"\n",
    "    Calculates MSE loss between max similarity of the candidates and similarity of top prediction.\n",
    "\n",
    "    Inputs:\n",
    "        score: torch.Size([<mentions>, <candidates>]) Float tensor resulting from matrix multiplication of mention and dictionary embeddings\n",
    "        target: torch.Size([<mentions>, <candidates>]) Similarity score (0,1] between candidates and gold CUIs for each mention.\n",
    "    \"\"\"\n",
    "    # Find the similarity score between the top prediction and gold CUI for each mention\n",
    "    # NOTE: This decouples the output of nn.forward() from the loss tensor returned. Are gradients stored on the outputs or on the model itself?\n",
    "    pred_ixs = score.argmax(dim=1)\n",
    "    predicted_similarity = torch.gather(target, 1, pred_ixs.unsqueeze_(dim=1)).squeeze().requires_grad_() \n",
    "\n",
    "    # Find max similarity score for each mention of the available candidates\n",
    "    expected_similarity = torch.max(target, dim=1).values\n",
    "\n",
    "    # Calculate MSE between the similarity score from the top prediction and the highest candidate similarity\n",
    "    return torch.nn.functional.mse_loss(expected_similarity, predicted_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('BioSyn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f1988f44dc5f1726269da6d50ac6138ff653bd316e3f250065b36ec61053392"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
