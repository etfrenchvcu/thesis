{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyarrow.feather as feather\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "processed_path = 'processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,844,773 concepts\n",
      "2,122,638 relationships\n"
     ]
    }
   ],
   "source": [
    "# Load filtered MRCONSO\n",
    "concepts = pd.read_feather(f'{processed_path}/mrconso.feather')[['CUI','STR','ISPREF']]\n",
    "concepts_cnt = '{:,}'.format(len(concepts))\n",
    "print(f'{concepts_cnt} concepts')\n",
    "\n",
    "# Load MRREL filtered to SNOMED and RxNorm\n",
    "rel = pd.read_feather(f'{processed_path}/mrrel.feather')[['CUI1','CUI2','REL']]\n",
    "rel_cnt = '{:,}'.format(len(rel))\n",
    "print(f'{rel_cnt} relationships')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUI</th>\n",
       "      <th>STR</th>\n",
       "      <th>ISPREF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31445</th>\n",
       "      <td>C0013528</td>\n",
       "      <td>Echolalia</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31446</th>\n",
       "      <td>C0013528</td>\n",
       "      <td>Echo speech</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31447</th>\n",
       "      <td>C0013528</td>\n",
       "      <td>Echolalia (finding)</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CUI                  STR ISPREF\n",
       "31445  C0013528            Echolalia      N\n",
       "31446  C0013528          Echo speech      Y\n",
       "31447  C0013528  Echolalia (finding)      Y"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts[concepts.CUI=='C0013528']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,061,319 unique relationships\n"
     ]
    }
   ],
   "source": [
    "# Check that every parent-child record has a symmetric child-parent\n",
    "par = (rel[rel.REL=='PAR'][['CUI2','CUI1']]\n",
    "    .sort_values(['CUI2','CUI1'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "par.columns = ['Parent','Child']\n",
    "chd = (rel[rel.REL=='CHD'][['CUI1','CUI2']]\n",
    "    .sort_values(['CUI1','CUI2'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "chd.columns = ['Parent','Child']\n",
    "\n",
    "assert par.equals(chd), \"Non-symmetric parent/child relationship present\"\n",
    "\n",
    "# Drop child half of symmetric relationships\n",
    "relations = par\n",
    "relation_cnt = '{:,}'.format(len(relations))\n",
    "print(f'{relation_cnt} unique relationships')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 13,442 relations merging child column\n",
      "Dropped 4,163 relations merging parent column\n",
      "1,043,714 relationships remaining\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Child</th>\n",
       "      <th>Parent</th>\n",
       "      <th>Child_Name</th>\n",
       "      <th>Parent_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0000300</td>\n",
       "      <td>C0000102</td>\n",
       "      <td>2-naphthylamine</td>\n",
       "      <td>1-naththylamine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Child    Parent       Child_Name      Parent_Name\n",
       "0  C0000300  C0000102  2-naphthylamine  1-naththylamine"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choosing a single preferred name per CUI\n",
    "pref_concepts = concepts[concepts.ISPREF=='Y'].drop_duplicates('CUI')\n",
    "assert len(pref_concepts.CUI)==len(set(pref_concepts.CUI)), \"Non-unique CUI\"\n",
    "\n",
    "# Join CUIs with names\n",
    "df = pd.merge(relations, pref_concepts, how=\"inner\", left_on=\"Child\", right_on=\"CUI\")\n",
    "length_after_merge = len(df)\n",
    "drop_cnt = '{:,}'.format(len(relations)-length_after_merge)\n",
    "print(f'Dropped {drop_cnt} relations merging child column')\n",
    "\n",
    "df = pd.merge(df, pref_concepts, how=\"inner\", left_on=\"Parent\", right_on=\"CUI\")\n",
    "drop_cnt = '{:,}'.format(length_after_merge-len(df))\n",
    "print(f'Dropped {drop_cnt} relations merging parent column')\n",
    "\n",
    "df = df[['Child','Parent','STR_x','STR_y']]\n",
    "df.columns = ['Child','Parent','Child_Name','Parent_Name']\n",
    "relation_cnt = '{:,}'.format(len(df))\n",
    "print(f'{relation_cnt} relationships remaining')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2-naphthylamine', 'C0000300'), ('4-nitroso dimethylamine', 'C0301275'), ('N-b-bis (2-chloroethyl)-2-naphthylamine', 'C0303972')]\n",
      "[('1-naththylamine', 'C0000102')]\n"
     ]
    }
   ],
   "source": [
    "# Build a dictionary of child names keyed on parent CUI\n",
    "children = {}\n",
    "for parent_cui, child in df.set_index('Parent')[['Child_Name','Child']].iterrows():\n",
    "    if parent_cui not in children:\n",
    "        children[parent_cui] = []\n",
    "    children[parent_cui].append((child.Child_Name,child.Child))\n",
    "\n",
    "with open(f'{processed_path}/children.pickle', 'wb') as f:\n",
    "    pickle.dump(children, f)\n",
    "\n",
    "# Build a dictionary of parents keyed on child CUI\n",
    "parents = {}\n",
    "for child_cui, parent in df.set_index('Child')[['Parent_Name','Parent']].iterrows():\n",
    "    if child_cui not in parents:\n",
    "        parents[child_cui] = []\n",
    "    parents[child_cui].append((parent.Parent_Name,parent.Parent))\n",
    "\n",
    "with open(f'{processed_path}/parents.pickle', 'wb') as f:\n",
    "    pickle.dump(parents, f)\n",
    "\n",
    "print(children['C0000102'])\n",
    "print(parents['C0000300'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dictionary of names to CUIs\n",
    "name_cuis = {}\n",
    "for i,d in concepts.iterrows():\n",
    "    if d.STR is None or d.CUI is None:\n",
    "        continue\n",
    "    name = d.STR.lower()\n",
    "    if name in name_cuis:\n",
    "        name_cuis[name] = name_cuis[name].union(set([d.CUI]))\n",
    "    else:\n",
    "        name_cuis[name] = set([d.CUI])\n",
    "with open(f'{processed_path}/name_cuis.pickle', 'wb') as f:\n",
    "    pickle.dump(name_cuis, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "# Helper methods\n",
    "def flatten(list):\n",
    "    \"Flatten a 2D list into 1D\"\n",
    "    return set([item for sublist in list for item in sublist])\n",
    "\n",
    "def parent_bfs(cuis, parent_dict):\n",
    "    \"Gets a unique set of parents for the list of CUIs\"\n",
    "    parents = []\n",
    "    for cui in cuis:\n",
    "        if cui in parent_dict:\n",
    "            parents += [c for _,c in parent_dict[cui]]\n",
    "    return set(parents)\n",
    "\n",
    "def extend_lineage(l_given, l_compare, parent_dict):\n",
    "    \"Extend a lineage up one level and check if the LCA is found\"\n",
    "    d = None\n",
    "    reached_root = False\n",
    "\n",
    "    # Breadth First Search next level of parents\n",
    "    parents = parent_bfs(l_given[-1], parent_dict)\n",
    "    parents = parents.difference(flatten(l_given))\n",
    "\n",
    "    if len(parents) > 0:\n",
    "        # Check for common ancestors (only need to check parents)\n",
    "        common_ancestors = flatten(l_compare).intersection(parents)\n",
    "        if len(common_ancestors) > 0:\n",
    "            for i, level in enumerate(l_compare):\n",
    "                if not level.isdisjoint(parents):\n",
    "                    d = len(l_given) + i\n",
    "                    break\n",
    "        l_given.append(parents)\n",
    "    else:\n",
    "        reached_root = True\n",
    "\n",
    "    # Return extended lineage and distance if found\n",
    "    return l_given, d, reached_root\n",
    "\n",
    "class Umls():\n",
    "    def __init__(self, path):\n",
    "        with open(f'{path}/children.pickle', 'rb') as f:\n",
    "            self.children = pickle.load(f)\n",
    "\n",
    "        with open(f'{path}/parents.pickle', 'rb') as f:\n",
    "            self.parents = pickle.load(f)\n",
    "\n",
    "    def get_candidates(self, cui:str, k:int):\n",
    "        \"Returns k ontological candidates for the specified CUI\"\n",
    "        candidates = set()\n",
    "\n",
    "        # Append up to half parent candidates\n",
    "        parents = []\n",
    "        if cui in self.parents:\n",
    "            parents = self.parents[cui]\n",
    "            if len(parents) > int(k/2):\n",
    "                parents = random.sample(parents, int(k/2))\n",
    "            candidates = candidates.union(set(parents))\n",
    "            k = k-len(candidates)\n",
    "\n",
    "        # Append children\n",
    "        kids = []\n",
    "        if cui in self.children:\n",
    "            kids = self.children[cui]\n",
    "            if len(kids) > k:\n",
    "                kids = random.sample(kids, k)\n",
    "            kids = set(kids).difference(candidates)\n",
    "            candidates = candidates.union(set(kids))\n",
    "            k = k-len(kids)\n",
    "\n",
    "        # Append siblings (children of parents) until k is reached\n",
    "        for _, parent_cui in parents:\n",
    "            if k == 0:\n",
    "                break\n",
    "            if parent_cui in self.children:\n",
    "                siblings = self.children[parent_cui]\n",
    "                if len(siblings) > k:\n",
    "                    siblings = random.sample(siblings, k)\n",
    "                siblings = set(siblings).difference(candidates)\n",
    "                candidates = candidates.union(set(siblings))\n",
    "                k = k-len(siblings)\n",
    "\n",
    "        # Append siblings (parents of children) until k is reached\n",
    "        for _, child_cui in kids:\n",
    "            if k == 0:\n",
    "                break\n",
    "            if child_cui in self.parents:\n",
    "                siblings = self.parents[child_cui]\n",
    "                if len(siblings) > k:\n",
    "                    siblings = random.sample(siblings, k)\n",
    "                siblings = set(siblings).difference(candidates)\n",
    "                candidates = candidates.union(set(siblings))\n",
    "                k = k-len(siblings)\n",
    "\n",
    "        # Fill in with empty strings if enough candidates can't be found\n",
    "        #TODO: Check that all candidates are in the dictionary?\n",
    "        #TODO: Return non-random options?\n",
    "        return [[n,c] for n,c in candidates]  + ([[\"NAME\",\"CUI\"]]*k)\n",
    "\n",
    "    def dist(self, cui1, cui2):\n",
    "        \"Finds the lowest common ancestor between two CUIs in the UMLS and calculates distance between them\"\n",
    "\n",
    "        # If CUIs are identical, distance is zero\n",
    "        if cui1==cui2:\n",
    "            return 0\n",
    "\n",
    "        lineage1 = [{cui1}]\n",
    "        lineage2 = [{cui2}]\n",
    "        reached_root1 = reached_root2 = False\n",
    "        while not reached_root1 or not reached_root2:\n",
    "            if not reached_root1:\n",
    "                lineage1, d, reached_root1 = extend_lineage(lineage1, lineage2, self.parents)\n",
    "                if d is not None: break\n",
    "\n",
    "            if not reached_root2:\n",
    "                lineage2, d, reached_root2 = extend_lineage(lineage2, lineage1, self.parents)\n",
    "                if d is not None: break\n",
    "\n",
    "        if reached_root1 and reached_root2:\n",
    "            d = len(lineage1) + len(lineage2)\n",
    "\n",
    "        if d is None:\n",
    "            print(\"THIS SHOULD NOT HAPPEN\")\n",
    "        return d\n",
    "\n",
    "    def similarity(self, cui1, cui2):\n",
    "        \"Calculates the ontological similarity between two CUIS\"\n",
    "        d = self.dist(cui1, cui2)\n",
    "        return 0 if d<0 else 1/(1+d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umls = Umls('processed')\n",
    "umls.dist('C0013516','C0013528')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Clinical history and observation findings', 'C0427350'),\n",
       " ('Speech and language finding', 'C0564649')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parents['C0562492']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
