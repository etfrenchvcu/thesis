{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for loading N2C2 Terminology file\n",
    "## All records must be:\n",
    "- From SNOMED-CT or RxNorm\n",
    "- Have a semantic type used by at least one CUI in the N2C2 training data\n",
    "- Be English language\n",
    "- Be not suppressible (MRCONSO.SUPPRESS!='E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyarrow.feather as feather\n",
    "import re\n",
    "\n",
    "raw_path = 'raw'\n",
    "processed_path = 'processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MRSTY.RRF \n",
    "UMLS semantic type mapping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'raw/MRSTY.RRF'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\etfrench\\code\\thesis\\umls\\load_mrconso.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/etfrench/code/thesis/umls/load_mrconso.ipynb#ch0000003?line=1'>2</a>\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mraw_path\u001b[39m}\u001b[39;00m\u001b[39m/MRSTY.RRF\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/etfrench/code/thesis/umls/load_mrconso.ipynb#ch0000003?line=2'>3</a>\u001b[0m cols \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mCUI\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mTUI\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mSTN\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mSTY\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mATUI\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mCVF\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mBLANK\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/etfrench/code/thesis/umls/load_mrconso.ipynb#ch0000003?line=3'>4</a>\u001b[0m mrsty \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_table(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mraw_path\u001b[39m}\u001b[39;49;00m\u001b[39m/MRSTY.RRF\u001b[39;49m\u001b[39m'\u001b[39;49m,sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m|\u001b[39;49m\u001b[39m'\u001b[39;49m,header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,names\u001b[39m=\u001b[39;49mcols)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/etfrench/code/thesis/umls/load_mrconso.ipynb#ch0000003?line=4'>5</a>\u001b[0m mrsty \u001b[39m=\u001b[39m mrsty[[\u001b[39m'\u001b[39m\u001b[39mTUI\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mCUI\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mSTY\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/etfrench/code/thesis/umls/load_mrconso.ipynb#ch0000003?line=5'>6</a>\u001b[0m mrsty\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mto_feather(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mprocessed_path\u001b[39m}\u001b[39;00m\u001b[39m/mrsty.feather\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\etfrench\\Anaconda3\\envs\\UMLS\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\etfrench\\Anaconda3\\envs\\UMLS\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:779\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    764\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    765\u001b[0m     dialect,\n\u001b[0;32m    766\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    775\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    776\u001b[0m )\n\u001b[0;32m    777\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 779\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\etfrench\\Anaconda3\\envs\\UMLS\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\etfrench\\Anaconda3\\envs\\UMLS\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\etfrench\\Anaconda3\\envs\\UMLS\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\etfrench\\Anaconda3\\envs\\UMLS\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'raw/MRSTY.RRF'"
     ]
    }
   ],
   "source": [
    "# Load MRSTY from source\n",
    "file = f'{raw_path}/MRSTY.RRF'\n",
    "cols = ['CUI','TUI','STN','STY','ATUI','CVF','BLANK']\n",
    "mrsty = pd.read_table(f'{raw_path}/MRSTY.RRF',sep='|',header=None,names=cols)\n",
    "mrsty = mrsty[['TUI','CUI','STY']]\n",
    "mrsty.reset_index(drop=True).to_feather(f'{processed_path}/mrsty.feather')\n",
    "mrsty.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MRCONSO.RRF \n",
    "UMLS metathesaurus file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etfrench\\AppData\\Local\\Temp\\ipykernel_21704\\2446371264.py:3: DtypeWarning: Columns (9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mrconso = pd.read_table(f'{raw_path}/MRCONSO.RRF',sep='|',header=None,names=cols)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUI</th>\n",
       "      <th>STR</th>\n",
       "      <th>ISPREF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C0000039</td>\n",
       "      <td>1,2-dipalmitoylphosphatidylcholine</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CUI                                 STR ISPREF\n",
       "9  C0000039  1,2-dipalmitoylphosphatidylcholine      N"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MRCONSO from source (Only needs to be done once)\n",
    "cols = ['CUI','LAT','TS','LUI','STT','SUI','ISPREF','AUI','SAUI','SCUI','SDUI','SAB','TTY','CODE','STR','SRL','SUPPRESS','CVF','BLANK']\n",
    "mrconso = pd.read_table(f'{raw_path}/MRCONSO.RRF',sep='|',header=None,names=cols)\n",
    "mrconso = mrconso.drop(columns=['BLANK'])\n",
    "umls = mrconso[mrconso.LAT=='ENG']\n",
    "umls = umls[(umls.SAB=='RXNORM') | (umls.SAB=='SNOMEDCT_US')]\n",
    "umls = umls[umls.SUPPRESS!='E'] # Seems like there are obsolete CUIs in the annotations...\n",
    "umls = umls[['CUI','STR','ISPREF']]\n",
    "umls.reset_index(drop=True).to_feather(f'{processed_path}/mrconso.feather')\n",
    "umls.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MRREL.RRF \n",
    "One-time load UMLS CUI relationship mapping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etfrench\\AppData\\Local\\Temp\\ipykernel_5360\\2793450661.py:4: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mrrel = pd.read_table(f'{raw_path}/MRREL.RRF',sep='|',header=None, names=names, usecols=usecols)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,122,638 raw relations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUI1</th>\n",
       "      <th>CUI2</th>\n",
       "      <th>REL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>C0000039</td>\n",
       "      <td>C0031610</td>\n",
       "      <td>PAR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CUI1      CUI2  REL\n",
       "80  C0000039  C0031610  PAR"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load raw MRREL from source, filter and save (Only needs to be done once)\n",
    "names = ['CUI1','AUI1','STYPE1','REL','CUI2','AUI2','STYPE2','RELA','RUI','SRUI','SAB','SL','RG','DIR','SUPPRESS','CVF','BLANK']\n",
    "usecols = ['CUI1','REL','CUI2','RELA','SAB','SL']\n",
    "mrrel = pd.read_table(f'{raw_path}/MRREL.RRF',sep='|',header=None, names=names, usecols=usecols)\n",
    "mrrel = mrrel[mrrel.SAB.isin(['SNOMEDCT_US','RXNORM'])]\n",
    "mrrel = mrrel[mrrel.REL.isin(['PAR','CHD'])][['CUI1','CUI2','REL']]\n",
    "mrrel = mrrel[mrrel.CUI1!=mrrel.CUI2]\n",
    "mrrel.reset_index(drop=True).to_feather(f'{processed_path}/mrrel.feather')\n",
    "\n",
    "mrrel_cnt = '{:,}'.format(len(mrrel))\n",
    "print(f'{mrrel_cnt} raw relations')\n",
    "mrrel.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload UMLS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "umls = pd.read_feather(f'{processed_path}/mrconso.feather')\n",
    "mrsty = pd.read_feather(f'{processed_path}/mrsty.feather')\n",
    "mrrel = pd.read_feather(f'{processed_path}/mrrel.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate list of semantic types appearing in training data\n",
    "We will use these to filter UMLS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etfrench\\AppData\\Local\\Temp\\ipykernel_5360\\756749720.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train = pd.read_table(train_path,sep='\\|\\|',header=None, names=['file_id','ix','type','name','CUI'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUI</th>\n",
       "      <th>name</th>\n",
       "      <th>file</th>\n",
       "      <th>TUI</th>\n",
       "      <th>STY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0011854</td>\n",
       "      <td>insulin dependent diabetes mellitus</td>\n",
       "      <td>0</td>\n",
       "      <td>T047</td>\n",
       "      <td>Disease or Syndrome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CUI                                 name file   TUI  \\\n",
       "0  C0011854  insulin dependent diabetes mellitus    0  T047   \n",
       "\n",
       "                   STY  \n",
       "0  Disease or Syndrome  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load a dataset of all training annotations\n",
    "train_path = '../datasets/n2c2/preprocessed/n2c2_traindev.concept'\n",
    "train = pd.DataFrame([])\n",
    "train = pd.read_table(train_path,sep='\\|\\|',header=None, names=['file_id','ix','type','name','CUI'])\n",
    "train['file'] = '0'\n",
    "train = train[['CUI','name','file']]\n",
    "train = pd.merge(train, mrsty, on='CUI')[['CUI','name','file','TUI','STY']]\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to derive N2C2_TUI\n",
    "# Get distinct TUI list in train order by # of CUIs in UMLS\n",
    "tuis = pd.merge(mrsty, pd.DataFrame(train.TUI.unique(), columns=['TUI']), on='TUI')\n",
    "tuis = tuis \\\n",
    "    .groupby('TUI').count()['CUI'] \\\n",
    "    .reset_index(name='count') \\\n",
    "    .sort_values(['count'], ascending=False) \\\n",
    "    .TUI.tolist()\n",
    "\n",
    "# Distinct CUIs when filtering to TUI list\n",
    "expected = len(set(train[train.TUI.isin(tuis)].CUI))\n",
    "removed = []\n",
    "\n",
    "for tui in tuis:\n",
    "    # Try removing records with given TUI\n",
    "    subset = train[(train.TUI.isin(tuis)) & (train.TUI != tui)]\n",
    "    \n",
    "    # If removing the TUI didn't drop unique CUIs, remove it permanently\n",
    "    if expected == len(set(subset.CUI)):\n",
    "        tuis.remove(tui)\n",
    "        removed.append(tui)\n",
    "        \n",
    "n2c2_tui = train[(train.TUI.isin(tuis))] \\\n",
    "    .groupby('TUI').count()['CUI'] \\\n",
    "    .reset_index(name='count') \\\n",
    "    .sort_values(['count'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate mrconso_dictionary.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etfrench\\AppData\\Local\\Temp\\ipykernel_5360\\2236879953.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  umls_term.STR = [x.lower().strip() for x in umls_term.STR]\n",
      "C:\\Users\\etfrench\\AppData\\Local\\Temp\\ipykernel_5360\\2236879953.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  umls_term.STR = umls_term.STR.str.replace('|'.join(qualifiers), '')\n",
      "C:\\Users\\etfrench\\AppData\\Local\\Temp\\ipykernel_5360\\2236879953.py:22: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  umls_term.STR = umls_term.STR.str.replace('|'.join(qualifiers), '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique CUIs: 548578\n",
      "Unique names: 984442\n"
     ]
    }
   ],
   "source": [
    "umls_term = umls[umls.STR.notnull()]\n",
    "umls_term.STR = [x.lower().strip() for x in umls_term.STR]\n",
    "\n",
    "# Filter by TUIs in N2C2 train\n",
    "umls_term = umls_term[['CUI','STR']]\n",
    "umls_term = pd.merge(umls_term, mrsty[['CUI','TUI']], on='CUI')\n",
    "umls_term = pd.merge(umls_term, n2c2_tui[['TUI']], on='TUI')\n",
    "umls_term = umls_term[['CUI','STR']]\n",
    "\n",
    "# Remove () qualifiers of the form \"acetylcysteine (substance)\" with >1000 instances\n",
    "series = umls_term[umls_term.STR.str.contains('\\(')].STR\n",
    "qualifiers = series.str.extract('(\\([^)]*\\))').groupby(0) \\\n",
    "    .filter(lambda x : len(x)>1000)[0].unique().tolist()\n",
    "qualifiers = [q.replace('(','\\(').replace(')','\\)') for q in qualifiers]\n",
    "umls_term.STR = umls_term.STR.str.replace('|'.join(qualifiers), '')\n",
    "\n",
    "# Remove [] qualifiers of the form \"[d]spots\"\n",
    "series = umls_term[umls_term.STR.str.contains('\\[[a-z]\\]')].STR\n",
    "qualifiers = series.str.extract('(\\[[a-z]\\])').groupby(0) \\\n",
    "    .filter(lambda x : len(x)>1)[0].unique().tolist()\n",
    "qualifiers = [q.replace('[','\\[').replace(']','\\]') for q in qualifiers]\n",
    "umls_term.STR = umls_term.STR.str.replace('|'.join(qualifiers), '')\n",
    "\n",
    "# Remove extra whitespace\n",
    "umls_term.STR = [re.sub(r'\\s+',' ',x) for x in umls_term.STR]\n",
    "umls_term.STR = [x.lower().strip() for x in umls_term.STR]\n",
    "umls_term = umls_term.drop_duplicates()\n",
    "umls_term = umls_term[umls_term.STR!='']\n",
    "\n",
    "print('Unique CUIs:', len(set(umls_term.CUI)))\n",
    "print('Unique names:', len(set(umls_term.STR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write mrconso_dictionary.txt\n",
    "with open('../datasets/n2c2/mrconso_dictionary.txt', 'w+') as f:\n",
    "    for x in umls_term.iterrows():\n",
    "        try:\n",
    "            f.write(f'{x[1].CUI}||{x[1].STR}\\n')\n",
    "        except:\n",
    "            print(f'{x[1].CUI}||{x[1].STR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dictionary of names to CUIs\n",
    "name_cuis = {}\n",
    "for i,d in umls_term.iterrows():\n",
    "    if d.STR is None or d.CUI is None:\n",
    "        continue\n",
    "    name = d.STR.lower()\n",
    "    if name in name_cuis:\n",
    "        name_cuis[name] = name_cuis[name].union(set([d.CUI]))\n",
    "    else:\n",
    "        name_cuis[name] = set([d.CUI])\n",
    "with open(f'{processed_path}/name_cuis.pickle', 'wb') as f:\n",
    "    pickle.dump(name_cuis, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etfrench\\AppData\\Local\\Temp\\ipykernel_5360\\89833707.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  cuis = pd.read_table(f'../datasets/n2c2/preprocessed/n2c2_{s}.concept', sep='\\|\\|',header=None)[4].unique()\n",
      "C:\\Users\\etfrench\\AppData\\Local\\Temp\\ipykernel_5360\\89833707.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  cuis = pd.read_table(f'../datasets/n2c2/preprocessed/n2c2_{s}.concept', sep='\\|\\|',header=None)[4].unique()\n",
      "C:\\Users\\etfrench\\AppData\\Local\\Temp\\ipykernel_5360\\89833707.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  cuis = pd.read_table(f'../datasets/n2c2/preprocessed/n2c2_{s}.concept', sep='\\|\\|',header=None)[4].unique()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2331\n",
      "CUIs missing from dictionary:  17\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n2c2_cuis = np.array([])\n",
    "for s in ['dev','train','test']:\n",
    "    cuis = pd.read_table(f'../datasets/n2c2/preprocessed/n2c2_{s}.concept', sep='\\|\\|',header=None)[4].unique()\n",
    "    n2c2_cuis = np.append(n2c2_cuis,cuis)\n",
    "n2c2_cuis = pd.DataFrame(set(n2c2_cuis), columns=['CUI'])\n",
    "print(len(n2c2_cuis))\n",
    "n2c2_cuis = pd.merge(n2c2_cuis, umls_term, on='CUI', how=\"left\")\n",
    "not_in_dict = n2c2_cuis[n2c2_cuis.STR.isnull()]\n",
    "print('CUIs missing from dictionary: ', len(not_in_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('UMLS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fa9a1dfa229c64dc67fe2c38c8680ec04e6e9810f35458aade5395baf6180889"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
